"""
ë°ì´í„° ìˆ˜ì§‘ê¸° ëª¨ë“ˆ
- KRXCollector: pykrx ê¸°ë°˜ ê°€ê²©/ìˆ˜ê¸‰ ë°ì´í„° ìˆ˜ì§‘
- EnhancedNewsCollector: ë„¤ì´ë²„/ë‹¤ìŒ ë‰´ìŠ¤ í¬ë¡¤ë§
"""

import asyncio
import aiohttp
from datetime import datetime, timedelta, date
from typing import List, Optional, Dict, Any
import pandas as pd
import re
from bs4 import BeautifulSoup

from engine.config import SignalConfig
from engine.models import StockData, NewsItem, SupplyData, ChartData


class KRXCollector:
    """KRX ë°ì´í„° ìˆ˜ì§‘ê¸° (pykrx ê¸°ë°˜)"""
    
    def __init__(self, config: SignalConfig = None):
        self.config = config or SignalConfig()
        self._session: Optional[aiohttp.ClientSession] = None
    
    async def __aenter__(self):
        self._session = aiohttp.ClientSession()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self._session:
            await self._session.close()
    
    async def get_top_gainers(self, market: str = "KOSPI", top_n: int = 30) -> List[StockData]:
        """ìƒìŠ¹ë¥  ìƒìœ„ ì¢…ëª© ì¡°íšŒ (FinanceDataReader ì‚¬ìš©)"""
        try:
            import FinanceDataReader as fdr
            
            # ì¢…ëª© ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            listing = await asyncio.to_thread(fdr.StockListing, market)
            
            if listing.empty:
                print(f"[{market}] ì¢…ëª© ëª©ë¡ ì—†ìŒ")
                return []
            
            # ìµœê·¼ 10ì¼ ì´ë‚´ ê±°ë˜ì¼ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            end_date = datetime.now()
            start_date = end_date - timedelta(days=10)
            
            stocks = []
            # ì‹œê°€ì´ì•¡ ìƒìœ„ ì¢…ëª©ë“¤ë§Œ ë¶„ì„ (ì†ë„ë¥¼ ìœ„í•´)
            top_stocks = listing.nlargest(100, 'Marcap') if 'Marcap' in listing.columns else listing.head(100)
            
            for _, row in top_stocks.iterrows():
                try:
                    code = row['Code']
                    name = row['Name']
                    
                    # ì œì™¸ í‚¤ì›Œë“œ ì²´í¬
                    if any(kw in name for kw in self.config.exclude_keywords):
                        continue
                    
                    # ê°œë³„ ì¢…ëª© ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                    df = await asyncio.to_thread(
                        fdr.DataReader, 
                        code, 
                        start_date.strftime("%Y-%m-%d"),
                        end_date.strftime("%Y-%m-%d")
                    )
                    
                    if df.empty or len(df) < 2:
                        continue
                    
                    latest = df.iloc[-1]
                    prev = df.iloc[-2]
                    
                    close = float(latest['Close'])
                    prev_close = float(prev['Close'])
                    change_pct = ((close - prev_close) / prev_close) * 100
                    volume = int(latest['Volume']) if 'Volume' in df.columns else 0
                    trading_value = close * volume
                    
                    # í•„í„°ë§
                    if change_pct < self.config.min_change_pct or change_pct > self.config.max_change_pct:
                        continue
                    if trading_value < self.config.min_trading_value:
                        continue
                    if close < self.config.min_price or close > self.config.max_price:
                        continue
                    
                    stocks.append(StockData(
                        code=code,
                        name=name,
                        market=market,
                        close=close,
                        open=float(latest['Open']) if 'Open' in df.columns else close,
                        high=float(latest['High']) if 'High' in df.columns else close,
                        low=float(latest['Low']) if 'Low' in df.columns else close,
                        change_pct=round(change_pct, 2),
                        volume=volume,
                        trading_value=int(trading_value),
                    ))
                    
                except Exception as e:
                    continue
            
            # ìƒìŠ¹ë¥  ìˆœ ì •ë ¬ í›„ ìƒìœ„ Nê°œ
            stocks.sort(key=lambda x: x.change_pct, reverse=True)
            
            # íœ´ì¥ì¼ ì—¬ë¶€ ì¶œë ¥
            if stocks:
                print(f"   ğŸ“… [{market}] {len(stocks)}ê°œ ì¢…ëª© ë¶„ì„ ì™„ë£Œ")
            
            return stocks[:top_n]
            
        except Exception as e:
            print(f"Error in get_top_gainers: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    async def get_stock_detail(self, code: str) -> Optional[StockData]:
        """ì¢…ëª© ìƒì„¸ ì •ë³´ ì¡°íšŒ"""
        try:
            from pykrx import stock
            
            today = datetime.now().strftime("%Y%m%d")
            start = (datetime.now() - timedelta(days=365)).strftime("%Y%m%d")
            
            # OHLCV ë°ì´í„°
            df = await asyncio.to_thread(
                stock.get_market_ohlcv,
                start, today, code
            )
            
            if df.empty:
                return None
            
            # 52ì£¼ ê³ ê°€/ì €ê°€
            high_52w = float(df['ê³ ê°€'].max())
            low_52w = float(df['ì €ê°€'].min())
            
            latest = df.iloc[-1]
            name = await asyncio.to_thread(stock.get_market_ticker_name, today, code)
            
            return StockData(
                code=code,
                name=name or code,
                market="",
                close=float(latest['ì¢…ê°€']),
                high_52w=high_52w,
                low_52w=low_52w,
            )
            
        except Exception as e:
            print(f"Error in get_stock_detail: {e}")
            return None
    
    async def get_chart_data(self, code: str, days: int = 60) -> List[ChartData]:
        """ì°¨íŠ¸ ë°ì´í„° ì¡°íšŒ"""
        try:
            from pykrx import stock
            
            today = datetime.now().strftime("%Y%m%d")
            start = (datetime.now() - timedelta(days=days * 2)).strftime("%Y%m%d")
            
            df = await asyncio.to_thread(
                stock.get_market_ohlcv,
                start, today, code
            )
            
            if df.empty:
                return []
            
            # ìµœê·¼ Nì¼ë§Œ
            df = df.tail(days)
            
            charts = []
            for idx, row in df.iterrows():
                charts.append(ChartData(
                    date=idx.strftime("%Y-%m-%d") if hasattr(idx, 'strftime') else str(idx),
                    open=float(row['ì‹œê°€']),
                    high=float(row['ê³ ê°€']),
                    low=float(row['ì €ê°€']),
                    close=float(row['ì¢…ê°€']),
                    volume=int(row['ê±°ë˜ëŸ‰']),
                ))
            
            return charts
            
        except Exception as e:
            print(f"Error in get_chart_data: {e}")
            return []
    
    async def get_supply_data(self, code: str) -> Optional[SupplyData]:
        """ìˆ˜ê¸‰ ë°ì´í„° ì¡°íšŒ (5ì¼/20ì¼ ëˆ„ì )"""
        try:
            from pykrx import stock
            
            today = datetime.now().strftime("%Y%m%d")
            start = (datetime.now() - timedelta(days=30)).strftime("%Y%m%d")
            
            df = await asyncio.to_thread(
                stock.get_market_net_purchases_of_equities,
                start, today, code
            )
            
            if df.empty:
                return None
            
            # ìµœê·¼ ë°ì´í„° ê¸°ì¤€
            recent_5d = df.tail(5)
            recent_20d = df.tail(20)
            
            foreign_5d = int(recent_5d['ì™¸êµ­ì¸í•©ê³„'].sum()) if 'ì™¸êµ­ì¸í•©ê³„' in df.columns else 0
            foreign_20d = int(recent_20d['ì™¸êµ­ì¸í•©ê³„'].sum()) if 'ì™¸êµ­ì¸í•©ê³„' in df.columns else 0
            inst_5d = int(recent_5d['ê¸°ê´€í•©ê³„'].sum()) if 'ê¸°ê´€í•©ê³„' in df.columns else 0
            inst_20d = int(recent_20d['ê¸°ê´€í•©ê³„'].sum()) if 'ê¸°ê´€í•©ê³„' in df.columns else 0
            
            # ì—°ì† ë§¤ìˆ˜ì¼ ê³„ì‚°
            foreign_consecutive = 0
            inst_consecutive = 0
            
            if 'ì™¸êµ­ì¸í•©ê³„' in df.columns:
                for val in df['ì™¸êµ­ì¸í•©ê³„'].iloc[::-1]:
                    if val > 0:
                        foreign_consecutive += 1
                    else:
                        break
            
            if 'ê¸°ê´€í•©ê³„' in df.columns:
                for val in df['ê¸°ê´€í•©ê³„'].iloc[::-1]:
                    if val > 0:
                        inst_consecutive += 1
                    else:
                        break
            
            is_double = foreign_5d > 0 and inst_5d > 0
            
            return SupplyData(
                code=code,
                foreign_buy_5d=foreign_5d,
                foreign_buy_20d=foreign_20d,
                foreign_consecutive_days=foreign_consecutive,
                inst_buy_5d=inst_5d,
                inst_buy_20d=inst_20d,
                inst_consecutive_days=inst_consecutive,
                is_double_buy=is_double,
            )
            
        except Exception as e:
            print(f"Error in get_supply_data: {e}")
            return None


class EnhancedNewsCollector:
    """ë‰´ìŠ¤ ìˆ˜ì§‘ê¸° (ë„¤ì´ë²„/ë‹¤ìŒ)"""
    
    MAJOR_SOURCES = {
        "í•œêµ­ê²½ì œ": 0.9,
        "ë§¤ì¼ê²½ì œ": 0.9,
        "ë¨¸ë‹ˆíˆ¬ë°ì´": 0.85,
        "ì„œìš¸ê²½ì œ": 0.85,
        "ì´ë°ì¼ë¦¬": 0.85,
        "ì—°í•©ë‰´ìŠ¤": 0.85,
        "ë‰´ìŠ¤1": 0.8,
        "í—¤ëŸ´ë“œê²½ì œ": 0.8,
        "íŒŒì´ë‚¸ì…œë‰´ìŠ¤": 0.8,
    }
    
    def __init__(self, config: SignalConfig = None):
        self.config = config or SignalConfig()
        self._session: Optional[aiohttp.ClientSession] = None
    
    async def __aenter__(self):
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        }
        self._session = aiohttp.ClientSession(headers=headers)
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self._session:
            await self._session.close()
    
    async def get_stock_news(self, code: str, limit: int = 5, name: str = "") -> List[NewsItem]:
        """ì¢…ëª©ë³„ ë‰´ìŠ¤ ì¡°íšŒ"""
        news_items = []
        
        try:
            # ë„¤ì´ë²„ ê¸ˆìœµ ë‰´ìŠ¤
            url = f"https://finance.naver.com/item/news_news.nhn?code={code}&page=1"
            
            async with self._session.get(url) as resp:
                if resp.status != 200:
                    return []
                
                html = await resp.text()
                soup = BeautifulSoup(html, 'html.parser')
                
                # ë‰´ìŠ¤ ëª©ë¡ íŒŒì‹±
                news_table = soup.find('table', class_='type5')
                if not news_table:
                    return []
                
                rows = news_table.find_all('tr')
                
                for row in rows[:limit * 2]:  # ì—¬ìœ ìˆê²Œ ê°€ì ¸ì˜´
                    title_tag = row.find('a', class_='tit')
                    if not title_tag:
                        continue
                    
                    title = title_tag.get_text(strip=True)
                    link = title_tag.get('href', '')
                    
                    # ë‚ ì§œ íŒŒì‹±
                    date_tag = row.find('td', class_='date')
                    date_str = date_tag.get_text(strip=True) if date_tag else ""
                    
                    # ì–¸ë¡ ì‚¬ íŒŒì‹±
                    source_tag = row.find('td', class_='info')
                    source = source_tag.get_text(strip=True) if source_tag else ""
                    
                    # ê´€ë ¨ë„ ê³„ì‚°
                    relevance = self.MAJOR_SOURCES.get(source, 0.7)
                    
                    news_items.append(NewsItem(
                        title=title,
                        summary="",  # ë³¸ë¬¸ì€ ë³„ë„ í˜¸ì¶œ í•„ìš”
                        source=source,
                        url=f"https://finance.naver.com{link}" if link.startswith('/') else link,
                        relevance=relevance,
                    ))
                    
                    if len(news_items) >= limit:
                        break
            
            # ë³¸ë¬¸ ìš”ì•½ ìˆ˜ì§‘ (ìƒìœ„ 3ê°œë§Œ)
            for i, news in enumerate(news_items[:3]):
                if news.url:
                    summary = await self._fetch_news_summary(news.url)
                    news.summary = summary
            
        except Exception as e:
            print(f"Error fetching news for {code}: {e}")
        
        return news_items
    
    async def _fetch_news_summary(self, url: str) -> str:
        """ë‰´ìŠ¤ ë³¸ë¬¸ ìš”ì•½ ì¶”ì¶œ"""
        try:
            async with self._session.get(url, timeout=aiohttp.ClientTimeout(total=5)) as resp:
                if resp.status != 200:
                    return ""
                
                html = await resp.text()
                soup = BeautifulSoup(html, 'html.parser')
                
                # ë³¸ë¬¸ ì¶”ì¶œ ì‹œë„
                content = None
                
                # ë„¤ì´ë²„ ê¸ˆìœµ ë‰´ìŠ¤ ë³¸ë¬¸
                content_div = soup.find('div', id='news_read')
                if content_div:
                    content = content_div.get_text(strip=True)
                
                if not content:
                    # ì¼ë°˜ ê¸°ì‚¬ ë³¸ë¬¸
                    article = soup.find('article') or soup.find('div', class_='article_body')
                    if article:
                        content = article.get_text(strip=True)
                
                if content:
                    # ì•ë¶€ë¶„ 200ìë§Œ ë°˜í™˜
                    content = re.sub(r'\s+', ' ', content)
                    return content[:200] + "..." if len(content) > 200 else content
                
        except Exception as e:
            pass
        
        return ""
